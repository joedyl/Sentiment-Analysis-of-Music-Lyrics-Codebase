{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding question ids with lowest agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "joe_final = pd.read_csv('./final_joe.csv')\n",
    "\n",
    "sinan_final = pd.read_csv('./final_sinan.csv')\n",
    "\n",
    "sam_final = pd.read_csv('./final_sam.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joely\\AppData\\Local\\Temp\\ipykernel_50660\\2529468228.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sinan_coord['rater_id'] = 1\n",
      "C:\\Users\\joely\\AppData\\Local\\Temp\\ipykernel_50660\\2529468228.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sam_coord['rater_id'] = 2\n",
      "C:\\Users\\joely\\AppData\\Local\\Temp\\ipykernel_50660\\2529468228.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  joe_coord['rater_id'] = 3\n",
      "C:\\Users\\joely\\AppData\\Local\\Temp\\ipykernel_50660\\2529468228.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sinan_coord['question_id'] = sinan_coord.index + 1\n",
      "C:\\Users\\joely\\AppData\\Local\\Temp\\ipykernel_50660\\2529468228.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sam_coord['question_id'] = sam_coord.index + 1\n",
      "C:\\Users\\joely\\AppData\\Local\\Temp\\ipykernel_50660\\2529468228.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  joe_coord['question_id'] = joe_coord.index + 1\n"
     ]
    }
   ],
   "source": [
    "sinan_coord = sinan_final[[\"x_coordinate\", \"y_coordinate\"]]\n",
    "\n",
    "\n",
    "sam_coord = sam_final[[\"x_coordinate\", \"y_coordinate\"]]\n",
    "\n",
    "\n",
    "joe_coord = joe_final[[\"x_coordinate\", \"y_coordinate\"]]\n",
    "\n",
    "sinan_coord['rater_id'] = 1\n",
    "sam_coord['rater_id'] = 2\n",
    "joe_coord['rater_id'] = 3\n",
    "\n",
    "sinan_coord['question_id'] = sinan_coord.index + 1\n",
    "sam_coord['question_id'] = sam_coord.index + 1\n",
    "joe_coord['question_id'] = joe_coord.index + 1\n",
    "\n",
    "sn_df = pd.merge(sinan_coord, sam_coord, on='question_id', suffixes=('_sinan', '_sam'))\n",
    "final_df = pd.merge(sn_df, joe_coord, on='question_id')\n",
    "final_df.rename(columns={'x_coordinate': 'x_coordinate_joe', 'y_coordinate': 'y_coordinate_joe'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define number of worst songs we want to retrieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_distance_func(a, b):\n",
    "    return abs(a - b) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to compute the distance between each song of each pair of annotators. We then add the values to get a total distance between annotators. This can then be stored on a new column in the dataframe, and the top N worst songs (in terms of agreement) can be retrieved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     question_id  total_distance\n",
      "121          122             3.0\n",
      "532          533             3.0\n",
      "182          183             3.0\n",
      "295          296             2.9\n",
      "186          187             2.8\n",
      "..           ...             ...\n",
      "36            37             1.2\n",
      "44            45             1.2\n",
      "123          124             1.2\n",
      "125          126             1.2\n",
      "141          142             1.2\n",
      "\n",
      "[500 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "def compute_distances(row):\n",
    "    sinan_sam = (custom_distance_func(row['x_coordinate_sinan'], row['x_coordinate_sam']),\n",
    "                               custom_distance_func(row['y_coordinate_sinan'], row['y_coordinate_sam']))\n",
    "    sinan_joe = (custom_distance_func(row['x_coordinate_sinan'], row['x_coordinate_joe']),\n",
    "                               custom_distance_func(row['y_coordinate_sinan'], row['y_coordinate_joe']))\n",
    "    sam_joe = (custom_distance_func(row['x_coordinate_sam'], row['x_coordinate_joe']),\n",
    "                             custom_distance_func(row['y_coordinate_sam'], row['y_coordinate_joe']))\n",
    "    \n",
    "    total_distance = sinan_sam[0] + sinan_sam[1] + sinan_joe[0] + sinan_joe[1] + sam_joe[0] + sam_joe[1]\n",
    "    return total_distance\n",
    "\n",
    "final_df['total_distance'] = final_df.apply(compute_distances, axis=1)\n",
    "\n",
    "#Get the top N songs with the worst agreement\n",
    "top_N_worst = final_df.nlargest(N, 'total_distance')\n",
    "\n",
    "print(top_N_worst[['question_id', 'total_distance']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_ids = top_N_worst.index.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating genres of lowest agreed 100 songs for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rap score: 90, Rb score: 88, rock score: 101, pop score: 117, country score: 104\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('final_joe.csv')\n",
    "\n",
    "tags = data['tag'].to_list()\n",
    "\n",
    "rap_score = 0\n",
    "rock_score = 0\n",
    "rb_score = 0\n",
    "pop_score = 0\n",
    "country_score = 0\n",
    "\n",
    "\n",
    "for id in bad_ids:\n",
    "    if tags[id] == 'rap':\n",
    "        rap_score += 1\n",
    "    if tags[id] == 'rock':\n",
    "        rock_score += 1\n",
    "    if tags[id] == 'rb':\n",
    "        rb_score += 1\n",
    "    if tags[id] == 'pop':\n",
    "        pop_score += 1\n",
    "    if tags[id] == 'country':\n",
    "        country_score += 1\n",
    "\n",
    "print(f\"Rap score: {rap_score}, Rb score: {rb_score}, rock score: {rock_score}, pop score: {pop_score}, country score: {country_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is after we reannotated. I am changing the reannotated values to 0 in dataset \n",
    "This will show up as having full agreement, which we now do.\n",
    "So we can calculate new agreement score after reannotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if N == 100:\n",
    "    joe_x = joe_final['x_coordinate'].to_list()\n",
    "    joe_y = joe_final['y_coordinate'].to_list()\n",
    "    sam_x = sam_final['x_coordinate'].to_list()\n",
    "    sam_y = sam_final['y_coordinate'].to_list()\n",
    "    sinan_x = sinan_final['x_coordinate'].to_list()\n",
    "    sinan_y = sinan_final['y_coordinate'].to_list()\n",
    "    for id in bad_ids:\n",
    "        joe_x[id] = 0\n",
    "        joe_y[id] = 0\n",
    "        sam_x[id] = 0\n",
    "        sam_y[id] = 0\n",
    "        sinan_x[id] = 0\n",
    "        sinan_y[id] = 0\n",
    "\n",
    "    joe_final['x_coordinate'] = joe_x\n",
    "    joe_final['y_coordinate'] = joe_y\n",
    "    sam_final['x_coordinate'] = sam_x\n",
    "    sam_final['y_coordinate'] = sam_y\n",
    "    sinan_final['x_coordinate'] = sinan_x\n",
    "    sinan_final['y_coordinate'] = sinan_y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if N == 100:\n",
    "    joe_final.to_csv('joe_new_agreed.csv')\n",
    "    sam_final.to_csv('sam_new_agreed.csv')\n",
    "    sinan_final.to_csv('sinan_new_agreed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping all bad ids to find the agreement scores of the top x of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "joe_worst_removed = joe_final.drop(index=bad_ids)\n",
    "\n",
    "sam_worst_removed = sam_final.drop(index=bad_ids)\n",
    "\n",
    "sinan_worst_removed = sinan_final.drop(index=bad_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "498"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(joe_worst_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "joe_worst_removed.to_csv('joe_worst_removed.csv')\n",
    "\n",
    "sam_worst_removed.to_csv('sam_worst_removed.csv')\n",
    "\n",
    "sinan_worst_removed.to_csv('sinan_worst_removed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Worst 200 removed gives: \n",
    "0.5313 for x_alpha\n",
    "0.3575 for y_alpha\n",
    "\n",
    "Worst 100 removed gives: \n",
    "0.4574 for x_alpha \n",
    "0.3126 for y_alpha\n",
    "\n",
    "Id be happy with worst 100, then if we have time, do more, the more the better. \n",
    "Worst 100 gives us moderate agreement (0.41-0.60) for x\n",
    "\n",
    "We didnt have time to do more than 100 in the end, annotating is very time consuming \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
